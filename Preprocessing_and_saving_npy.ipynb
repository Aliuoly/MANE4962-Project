{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkFMZx0t5hkX"
      },
      "source": [
        "# Import modules and connect drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VyuVX9s5o5y",
        "outputId": "35a9fa33-2314-4e32-a176-11c8d8c32f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import shutil\n",
        "import random\n",
        "import time\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b9Xq2dH6F2u"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_pitch_and_velocity(json_path, file_names):\n",
        "    \"\"\"\n",
        "    Retrieve the pitch and velocity information of the files in file_names using\n",
        "    the json file in json_path\n",
        "\n",
        "    Parameters:\n",
        "    json_path  (str): location of the json file\n",
        "    file_names (str): name of files for which to retrieve pitch and velocity\n",
        "\n",
        "    Returns:\n",
        "    pitch (ndarray)\n",
        "    velocity (ndarray)\n",
        "\n",
        "    \"\"\"\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    file_data = [data[file_name] for file_name in file_names]\n",
        "    pitch = [file_datum['pitch'] for file_datum in file_data]\n",
        "    velocity = [file_datum['velocity'] for file_datum in file_data]\n",
        "    \n",
        "    return pitch,velocity\n",
        "\n",
        "class Loader:\n",
        "    \"\"\"Loader is responsible for loading an audio file.\"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate, duration, mono):\n",
        "        self.sample_rate = sample_rate\n",
        "        self.duration = duration\n",
        "        self.mono = mono\n",
        "\n",
        "    def load(self, file_path):\n",
        "        signal = librosa.load(file_path,\n",
        "                              sr=self.sample_rate,\n",
        "                              duration=self.duration,\n",
        "                              mono=self.mono)[0]\n",
        "        return signal\n",
        "\n",
        "\n",
        "class Padder:\n",
        "    \"\"\"Padder is responsible to apply padding to an array.\"\"\"\n",
        "\n",
        "    def __init__(self, mode=\"constant\"):\n",
        "        self.mode = mode\n",
        "\n",
        "    def left_pad(self, array, num_missing_items):\n",
        "        padded_array = np.pad(array,\n",
        "                              (num_missing_items, 0),\n",
        "                              mode=self.mode)\n",
        "        return padded_array\n",
        "\n",
        "    def right_pad(self, array, num_missing_items):\n",
        "        padded_array = np.pad(array,\n",
        "                              (0, num_missing_items),\n",
        "                              mode=self.mode)\n",
        "        return padded_array\n",
        "\n",
        "\n",
        "class LogSpectrogramExtractor:\n",
        "    \"\"\"LogSpectrogramExtractor extracts log spectrograms (in dB) from a\n",
        "    time-series signal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, frame_size, hop_length):\n",
        "        self.frame_size = frame_size\n",
        "        self.hop_length = hop_length\n",
        "\n",
        "    def extract(self, signal):\n",
        "        stft = librosa.stft(signal,\n",
        "                            n_fft=self.frame_size,\n",
        "                            hop_length=self.hop_length,center=True)[:-1]\n",
        "        spectrogram = np.abs(stft)\n",
        "        phase_spectrogram = np.angle(stft)\n",
        "        log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
        "        return log_spectrogram, phase_spectrogram\n",
        "\n",
        "\n",
        "class MinMaxNormaliser:\n",
        "    \"\"\"MinMaxNormaliser applies min max normalisation to an array.\"\"\"\n",
        "\n",
        "    def __init__(self, min_val, max_val):\n",
        "        self.min = min_val\n",
        "        self.max = max_val\n",
        "\n",
        "    def normalise(self, array):\n",
        "        norm_array = (array - array.min()) / (array.max() - array.min())\n",
        "        norm_array = norm_array * (self.max - self.min) + self.min\n",
        "        return norm_array\n",
        "\n",
        "    def denormalise(self, norm_array, original_min, original_max):\n",
        "        array = (norm_array - self.min) / (self.max - self.min)\n",
        "        array = array * (original_max - original_min) + original_min\n",
        "        return array\n",
        "\n",
        "\n",
        "class Saver:\n",
        "    \"\"\"saver is responsible to save features, and the min max values.\"\"\"\n",
        "\n",
        "    def __init__(self, feature_save_dir1, feature_save_dir2, min_max_values_save_dir):\n",
        "        self.feature_save_dir1 = feature_save_dir1\n",
        "        self.feature_save_dir2 = feature_save_dir2\n",
        "        self.min_max_values_save_dir = min_max_values_save_dir\n",
        "\n",
        "    def save_feature1(self, feature, file_path):\n",
        "        save_path = self._generate_save_path1(file_path)\n",
        "        np.save(save_path, feature)\n",
        "        return save_path\n",
        "\n",
        "    def save_feature2(self, feature, file_path):\n",
        "        save_path = self._generate_save_path2(file_path)\n",
        "        np.save(save_path, feature)\n",
        "        return save_path\n",
        "\n",
        "    def save_min_max_values(self, min_max_values):\n",
        "        save_path = os.path.join(self.min_max_values_save_dir,\n",
        "                                 \"min_max_values.pkl\")\n",
        "        self._save(min_max_values, save_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def _save(data, save_path):\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def _generate_save_path1(self, file_path):\n",
        "        file_name = os.path.split(file_path)[1]\n",
        "        save_path = os.path.join(self.feature_save_dir1, file_name + \".npy\")\n",
        "        return save_path\n",
        "\n",
        "    def _generate_save_path2(self, file_path):\n",
        "        file_name = os.path.split(file_path)[1]\n",
        "        save_path = os.path.join(self.feature_save_dir2, file_name + \".npy\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "class PreprocessingPipeline:\n",
        "    \"\"\"PreprocessingPipeline processes audio files in a directory, applying\n",
        "    the following steps to each file:\n",
        "        1- load a file\n",
        "        2- pad the signal (if necessary)\n",
        "        3- extracting log spectrogram from signal\n",
        "        4- normalise spectrogram\n",
        "        5- save the normalised spectrogram\n",
        "    Storing the min max values for all the log spectrograms.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.padder = None\n",
        "        self.extractor = None\n",
        "        self.normaliser = None\n",
        "        self.saver = None\n",
        "        self.min_max_values = {}\n",
        "        self._loader = None\n",
        "        self._num_expected_samples = None\n",
        "\n",
        "    @property\n",
        "    def loader(self):\n",
        "        return self._loader\n",
        "\n",
        "    @loader.setter\n",
        "    def loader(self, loader):\n",
        "        self._loader = loader\n",
        "        self._num_expected_samples = int(loader.sample_rate * loader.duration)\n",
        "\n",
        "    def process(self, audio_files_dir):\n",
        "        start_time = time.time()\n",
        "        num_files_written = 0\n",
        "        for root, _, files in os.walk(audio_files_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                self._process_file(file_path)\n",
        "                print(f\"Processed file {file_path}\")\n",
        "                num_files_written += 1\n",
        "                elapsed_time = time.time() - start_time\n",
        "                avg_time_per_file = elapsed_time / num_files_written\n",
        "                remaining_files = len(files) - num_files_written\n",
        "                eta = avg_time_per_file * remaining_files\n",
        "                print(f\"ETA: {eta:.2f} seconds\")\n",
        "\n",
        "        self.saver.save_min_max_values(self.min_max_values)\n",
        "\n",
        "    def _process_file(self, file_path):\n",
        "        signal = self.loader.load(file_path)\n",
        "        if self._is_padding_necessary(signal):\n",
        "            signal = self._apply_padding(signal)\n",
        "        log_spec,phase_spec = self.extractor.extract(signal)\n",
        "\n",
        "        #magnitude\n",
        "        norm_feature = self.normaliser.normalise(log_spec)\n",
        "        save_path = self.saver.save_feature1(norm_feature, file_path)\n",
        "\n",
        "        #phase\n",
        "        \n",
        "        self.saver.save_feature2(phase_spec, file_path)\n",
        "        self._store_min_max_value(save_path, log_spec.min(), log_spec.max())\n",
        "\n",
        "    def _is_padding_necessary(self, signal):\n",
        "        if len(signal) < self._num_expected_samples:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _apply_padding(self, signal):\n",
        "        num_missing_samples = self._num_expected_samples - len(signal)\n",
        "        padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
        "        return padded_signal\n",
        "\n",
        "    def _store_min_max_value(self, save_path, min_val, max_val):\n",
        "        self.min_max_values[save_path] = {\n",
        "            \"min\": min_val,\n",
        "            \"max\": max_val\n",
        "        }\n",
        "\n",
        "def generate_log_spectrogram_and_save(SAMPLE_RATE,DURATION,MONO,FRAME_SIZE,HOP_LENGTH,SPECTROGRAMS_SAVE_DIR,phase_save_dir,MIN_MAX_VALUES_SAVE_DIR):\n",
        "    \"as the name suggests\"\n",
        "    loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
        "    padder = Padder()\n",
        "    log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
        "    min_max_normaliser = MinMaxNormaliser(0, 1)\n",
        "    saver = Saver(SPECTROGRAMS_SAVE_DIR, phase_save_dir, MIN_MAX_VALUES_SAVE_DIR)\n",
        "\n",
        "    preprocessing_pipeline = PreprocessingPipeline()\n",
        "    preprocessing_pipeline.loader = loader\n",
        "    preprocessing_pipeline.padder = padder\n",
        "    preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
        "    preprocessing_pipeline.normaliser = min_max_normaliser\n",
        "    preprocessing_pipeline.saver = saver\n",
        "\n",
        "    preprocessing_pipeline.process(FILES_DIR)\n",
        "\n",
        "\n",
        "def save_ndarray_as_npy_files(array, save_path, file_name):\n",
        "    \"\"\"\n",
        "    save the passed ndarray as an npy file\n",
        "    \n",
        "    \"\"\"\n",
        "    save_path = os.path.join(save_path, file_name + '.npy')\n",
        "    np.save(save_path, array)\n",
        "\n",
        "def move_acoustic_wav_to_new_folder(input_folder,output_folder):\n",
        "    \n",
        "    \"\"\"\n",
        "    only ran once to move the acoustic files to another directory\n",
        "    \"\"\"\n",
        "\n",
        "    # iterate over all files in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "      if filename.endswith(\".wav\") and filename.startswith(\"keyboard_acoustic\"):\n",
        "          # construct the full input and output file paths\n",
        "          input_path = os.path.join(input_folder, filename)\n",
        "          print(input_path)\n",
        "          output_path = os.path.join(output_folder, filename)\n",
        "          \n",
        "          # move the file from the input folder to the output folder\n",
        "          shutil.move(input_path, output_path)\n",
        "          print(f\"Processed file {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTu9Bh-EGzMk"
      },
      "source": [
        "# Pre processing and storing data as .npy for use in other file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlyF2KDa7NRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "51515b78-1e99-411b-b1e2-21c26025e4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 15/8068 [01:01<9:14:06,  4.13s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-41be0cd0922a>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mFILES_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic wav files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mgenerate_log_spectrogram_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDURATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMONO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHOP_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_SPECTROGRAMS_SAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPHASE_SPECTROGRAMS_SAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMIN_MAX_VALUES_SAVE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#Compile the spectrograms into a 3darray, keep all data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-98b052045e7d>\u001b[0m in \u001b[0;36mgenerate_log_spectrogram_and_save\u001b[0;34m(SAMPLE_RATE, DURATION, MONO, FRAME_SIZE, HOP_LENGTH, SPECTROGRAMS_SAVE_DIR, phase_save_dir, MIN_MAX_VALUES_SAVE_DIR)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mpreprocessing_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m     \u001b[0mpreprocessing_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILES_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSoundGenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-98b052045e7d>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, audio_files_dir)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0;31m#print(f\"Processed file {file_path}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mnum_files_written\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-98b052045e7d>\u001b[0m in \u001b[0;36m_process_file\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m#phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_feature2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_min_max_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-98b052045e7d>\u001b[0m in \u001b[0;36msave_feature2\u001b[0;34m(self, feature, file_path)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_feature2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_save_path2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mfile_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#move acoustic sound samples to a new folder to prepare for generating spectrograms if needed\n",
        "move_acoustic = False\n",
        "if move_acoustic:\n",
        "  move_acoustic_wav_to_new_folder(input_folder = '/content/drive/MyDrive/output',output_folder = '/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic wav files')\n",
        "\n",
        "do_preprocess = True\n",
        "if do_preprocess:\n",
        "\n",
        "    #generate spectrograms from the acoustic.wav files if needed\n",
        "    generate_spectrograms = True\n",
        "    if generate_spectrograms:\n",
        "      n_fft = 2048\n",
        "      HOP_LENGTH = 256\n",
        "      DURATION = 3  # in seconds #only the first 3 seconds, skip the release part (last second)\n",
        "      SAMPLE_RATE = 16000\n",
        "      MONO = True\n",
        "\n",
        "      #whole_spectrogram_save_dir = '/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic spectrograms'\n",
        "\n",
        "      log_SPECTROGRAMS_SAVE_DIR = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_log_spectrograms\"\n",
        "      PHASE_SPECTROGRAMS_SAVE_DIR = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_phase_spectrograms\"\n",
        "      MIN_MAX_VALUES_SAVE_DIR = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_log_MinMaxVals\"\n",
        "      FILES_DIR = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic wav files\"\n",
        "\n",
        "      generate_log_spectrogram_and_save(SAMPLE_RATE,DURATION,MONO,n_fft,HOP_LENGTH,log_SPECTROGRAMS_SAVE_DIR,PHASE_SPECTROGRAMS_SAVE_DIR,MIN_MAX_VALUES_SAVE_DIR)\n",
        "\n",
        "    #Compile the spectrograms into a 3darray, keep all data\n",
        "    compile_spectrograms_into_3darray = True\n",
        "    if compile_spectrograms_into_3darray:\n",
        "        x_train_log,log_file_names = load_and_sample_npy_files(folder_path = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_log_spectrograms\", sample_percentage=1)\n",
        "        #get phase data based on the file names of x_train_log. ensures correct ordering\n",
        "        x_train_phase,_ = load_and_sample_npy_files(folder_path =\"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_phase_spectrograms\", sample_percentage=1, file_names_criteria = log_file_names)\n",
        "\n",
        "        #get sine and cosine component and stack x_train\n",
        "        x_train_sine = np.sin(x_train_phase)\n",
        "        x_train_cos = np.cos(x_train_phase)\n",
        "\n",
        "        x_train = np.concatenate((x_train_log, x_train_sine, x_train_cos), axis=3)\n",
        "\n",
        "\n",
        "        #x_train is 256x251x1. Need it to be 256x256x1. Will pad with zeros. \n",
        "        x_train = np.pad(x_train, ((0, 0), (0, 0), (0, 5), (0, 0)), mode='constant')\n",
        "\n",
        "    #Get the pitch and velocity values for each training data\n",
        "    do_get_pitch_and_velocity = True\n",
        "    if do_get_pitch_and_velocity:\n",
        "        field_names = [file_name[:-8] for file_name in log_file_names]#the [:-4] removes the .npy extension\n",
        "        pitch, velocity = get_pitch_and_velocity(json_path='/content/drive/MyDrive/Variational_Auto_Encoder/examples.json', file_names=field_names)\n",
        "        label_train = np.vstack((pitch,velocity))\n",
        "\n",
        "    #Save the training ndarray as .npy. Also save the pitch and velocity\n",
        "    save_train_and_label_and_filenames = True\n",
        "    if save_train_and_label_and_filenames:\n",
        "        save_ndarray_as_npy_files(x_train, save_path='/content/drive/MyDrive/Variational_Auto_Encoder/training data', file_name='x_train_all_acoustic')\n",
        "        save_ndarray_as_npy_files(label_train, save_path='/content/drive/MyDrive/Variational_Auto_Encoder/training data', file_name='pitch_and_velocity_train_all_acoustic')\n",
        "        save_ndarray_as_npy_files(log_file_names, save_path='/content/drive/MyDrive/Variational_Auto_Encoder/training data', file_name='file_names_train_all_acoustic')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}