{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOdp4YCpg1hD",
        "outputId": "0d5ab447-b0f7-42a8-f86c-22202b0cf2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.9/dist-packages (0.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (2.13.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "eIcHl4Img4v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_encoder_decoder(input_shape, conv_filters, conv_kernels, conv_strides, latent_dim, pre_latent_dense_size_factor=None, decoder_activation=\"sigmoid\",dropout_rate=0.1,mode = \"VAE\"):\n",
        "    encoder_inputs = keras.Input(shape=input_shape, name=\"encoder_input\")\n",
        "    num_layers = len(conv_filters)\n",
        "    print(\"buildmode\")\n",
        "    print(mode)\n",
        "    # Encoder\n",
        "    residual_connections = []\n",
        "    for layer in range(num_layers):\n",
        "        if layer == 0:\n",
        "            x = layers.Conv2D(conv_filters[layer], conv_kernels[layer], strides=conv_strides[layer], padding=\"same\", name=f\"encoder_conv_layer_{layer+1}\")(encoder_inputs)\n",
        "        else:\n",
        "            x = layers.Conv2D(conv_filters[layer], conv_kernels[layer], strides=conv_strides[layer], padding=\"same\", name=f\"encoder_conv_layer_{layer+1}\")(x)\n",
        "        \n",
        "        x = layers.LeakyReLU(name=f\"encoder_LeakyReLU_{layer+1}\")(x)\n",
        "        x = layers.Dropout(dropout_rate, name=f\"encoder_dropout_{layer+1}\")(x)\n",
        "        x = layers.BatchNormalization(name=f\"encoder_BN_{layer+1}\")(x)\n",
        "\n",
        "        if layer % 2 == 0:\n",
        "            residual_connections.append(x)\n",
        "\n",
        "        if layer % 2 == 1:\n",
        "            x_residual = layers.Conv2D(conv_filters[layer], 1, strides=conv_strides[layer], padding=\"same\", name=f\"encoder_residual_conv_{layer}\")(residual_connections.pop())\n",
        "            x = layers.Add(name=f\"encoder_residual_add_{layer}\")([x, x_residual])\n",
        "\n",
        "    shape_before_bottleneck = K.int_shape(x)[1:]\n",
        "    num_neurons = np.prod(shape_before_bottleneck)\n",
        "    x = layers.Flatten(name=\"encoder_flatten\")(x)\n",
        "    x = layers.LeakyReLU(name=\"encoder_flattened_LeakyReLU\")(x)\n",
        "    x = layers.Dropout(dropout_rate, name=f\"encoder_dropout_flatten\")(x)\n",
        "\n",
        "    if pre_latent_dense_size_factor:\n",
        "        x = layers.Dense(latent_dim * pre_latent_dense_size_factor, name=\"encoder_pre_latent_dense\")(x)\n",
        "        x = layers.LeakyReLU(name=\"encoder_dense_LeakyReLU\")(x)\n",
        "        x = layers.Dropout(dropout_rate, name=f\"encoder_dropout_pre_latent_dense\")(x)\n",
        "\n",
        "    if mode == \"VAE\":\n",
        "      z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "      z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "      z = Sampling(name=\"latent_sample\")([z_mean, z_log_var])\n",
        "\n",
        "      encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "    else:\n",
        "      z = layers.Dense(latent_dim, name=\"z\")(x)\n",
        "      encoder = keras.Model(encoder_inputs, z, name=\"encoder\")\n",
        "\n",
        "    encoder.summary()\n",
        "\n",
        "    # Decoder\n",
        "    latent_inputs = keras.Input(shape=(latent_dim,), name=\"decoder_input\")\n",
        "    if pre_latent_dense_size_factor:\n",
        "        x = layers.Dense(latent_dim * pre_latent_dense_size_factor, name=\"decoder_post_latent_dense\")(latent_inputs)\n",
        "        x = layers.LeakyReLU(name=\"decoder_dense_LeakyReLU\")(x)\n",
        "        x = layers.Dropout(dropout_rate, name=f\"edecoder_dropout_post_latent_dense\")(x)\n",
        "        x = layers.Dense(num_neurons, name=\"decoder_upsize\")(x)\n",
        "    else:\n",
        "        x = layers.Dense(num_neurons, name=\"decoder_upsize\")(latent_inputs)\n",
        "\n",
        "    x = layers.LeakyReLU(name=\"decoder_pre_unflatten_LeakyReLU\")(x)\n",
        "    x = layers.Dropout(dropout_rate, name=f\"decoder_dropout_unflatten\")(x)\n",
        "    x = layers.Reshape(shape_before_bottleneck, name=\"decoder_unflatten\")(x)\n",
        "\n",
        "    residual_connections = []\n",
        "    for layer in range(num_layers - 1):\n",
        "        inverted_layer = num_layers - layer - 1\n",
        "        x = layers.Conv2DTranspose(conv_filters[inverted_layer], conv_kernels[inverted_layer], strides=conv_strides[inverted_layer], padding=\"same\", name=f\"decoder_conv_layer_{layer+1}\")(x)\n",
        "        x = layers.LeakyReLU(name=f\"decoder_LeakyReLU_{layer+1}\")(x)\n",
        "        \n",
        "        x = layers.Dropout(dropout_rate, name=f\"decoder_dropout_{layer+1}\")(x)\n",
        "\n",
        "        x = layers.BatchNormalization(name=f\"decoder_BN_{layer+1}\")(x)\n",
        "        if layer % 2 == 0:\n",
        "            residual_connections.append(x)\n",
        "\n",
        "        if layer % 2 == 1:\n",
        "            x_residual = layers.Conv2DTranspose(conv_filters[inverted_layer], 1, strides=conv_strides[inverted_layer], padding=\"same\", name=f\"decoder_residual_conv_{layer}\")(residual_connections.pop())\n",
        "            x = layers.Add(name=f\"decoder_residual_add_{layer}\")([x, x_residual])\n",
        "\n",
        "    decoder_outputs = layers.Conv2DTranspose(input_shape[-1], conv_kernels[0], activation=decoder_activation, strides=conv_strides[0], padding=\"same\", name=f\"decoder_output\")(x)\n",
        "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "    decoder.summary()\n",
        "\n",
        "    return encoder, decoder"
      ],
      "metadata": {
        "id": "mWu8ydxOgu4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class CombinedMetricEarlyStopping(Callback):\n",
        "    def __init__(self, monitor=\"val_ssim\", mode=\"max\", patience=30, min_delta=0.01, restore_best_weights=True):\n",
        "        super().__init__()\n",
        "        self.monitor = monitor\n",
        "        self.mode = mode\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.best_weights = None\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.best = float(\"-inf\") if self.mode == \"max\" else float(\"inf\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current = logs.get(self.monitor) \n",
        "        if current is None:\n",
        "            print(f\"Early stopping conditioned on metric `{self.monitor}` which is not available. Available metrics are: {','.join(list(logs.keys()))}\")\n",
        "            return\n",
        "\n",
        "        if self.mode == \"max\":\n",
        "          if current < self.best - self.min_delta*self.best: #give some slack\n",
        "            is_better = False\n",
        "          else:\n",
        "            is_better = current > self.best\n",
        "            \n",
        "        else:\n",
        "          if current > self.best + self.min_delta*self.best:\n",
        "            is_better = False\n",
        "          else:\n",
        "            is_better = current < self.best\n",
        "\n",
        "        if is_better:\n",
        "            print(\"saving best weights\")\n",
        "            print(f\"previous best={self.best}\")\n",
        "            print(f\"new best={current}\")\n",
        "            print(self.mode)\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            \n",
        "            \n",
        "\n",
        "            if self.restore_best_weights:\n",
        "                self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                if self.restore_best_weights:\n",
        "                    self.model.set_weights(self.best_weights)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(f\"Epoch {self.stopped_epoch + 1}: early stopping\")\n",
        "\n",
        "def pitch_weight(pitch, min_weight=1, max_weight=10):\n",
        "    min_hz, max_hz = 0, 4000\n",
        "    \n",
        "    # Convert pitch to frequency (Hz)\n",
        "    hz = 2**((pitch - 69) / 12) * 440\n",
        "    \n",
        "    # Scale weight based on frequency\n",
        "    weight_range = max_weight - min_weight\n",
        "    normalized_hz = 1 - (hz - min_hz) / (max_hz - min_hz)  # Flip the weights\n",
        "    weight = min_weight + (normalized_hz * weight_range)\n",
        "    return weight\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, loss_type=\"binary_crossentropy\", mode = \"VAE\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.mode = mode\n",
        "        print(self.mode)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.loss_type = loss_type\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "        self.ssim_tracker = keras.metrics.Mean(name=\"ssim\")\n",
        "        self.combined_metric_tracker = keras.metrics.Mean(name=\"combined_kl_ssim\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "            self.ssim_tracker,\n",
        "        ]\n",
        "    def call(self, inputs):\n",
        "        if self.mode == \"VAE\":\n",
        "          z_mean, z_log_var, z = self.encoder(inputs)\n",
        "          reconstruction = self.decoder(z)\n",
        "          kl_loss = -0.5 * (\n",
        "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "          )\n",
        "          kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "        else:\n",
        "          z = self.encoder(inputs)\n",
        "          reconstruction = self.decoder(z)\n",
        "          kl_loss = 0\n",
        "        return reconstruction, kl_loss\n",
        "\n",
        "    def train_step(self, data_and_labels):\n",
        "      \n",
        "      #reset just the combined and ssim tracker - better intuition to clear the huge values from first epoch..\n",
        "      self.combined_metric_tracker.reset_states()\n",
        "      #self.ssim_tracker.reset_states()\n",
        "\n",
        "      data, pitch_labels = data_and_labels\n",
        "      #print(data.shape)\n",
        "      #print(pitch_labels.shape)\n",
        "      with tf.GradientTape() as tape:\n",
        "        reconstruction, kl_loss = self(data)\n",
        "\n",
        "        if self.loss_type == \"binary_crossentropy\":\n",
        "            reconstruction_loss = keras.losses.binary_crossentropy(data, reconstruction)\n",
        "        elif self.loss_type == \"mean_squared_error\":\n",
        "            reconstruction_loss = keras.losses.mean_squared_error(data, reconstruction)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported loss type: {self.loss_type}\")\n",
        "\n",
        "        # Scale the reconstruction loss by pitch-dependent weight - as the NSynth people did\n",
        "        pitch_weights = tf.vectorized_map(pitch_weight, pitch_labels)\n",
        "        pitch_weights = tf.expand_dims(pitch_weights, axis=-1)\n",
        "        #print(pitch_weights.shape)\n",
        "        #print(reconstruction_loss.shape)\n",
        "        weighted_reconstruction_loss = pitch_weights * reconstruction_loss\n",
        "\n",
        "        # reduce the losses\n",
        "        reconstruction_loss = tf.reduce_mean(\n",
        "            tf.reduce_sum(\n",
        "                reconstruction_loss,\n",
        "                axis=(1, 2),\n",
        "            )\n",
        "        )\n",
        "        weighted_reconstruction_loss = tf.reduce_mean(\n",
        "            tf.reduce_sum(\n",
        "                weighted_reconstruction_loss,\n",
        "                axis=(1, 2),\n",
        "            )\n",
        "        )\n",
        "        # combine the losses\n",
        "        if self.mode == \"VAE\":\n",
        "          total_loss = weighted_reconstruction_loss + 100 * kl_loss\n",
        "        else:\n",
        "          total_loss = weighted_reconstruction_loss\n",
        "\n",
        "        ## get ssim metrics\n",
        "        ssim = tf.reduce_mean(tf.image.ssim(data, reconstruction, max_val=1.0))\n",
        "        combined_kl_ssim_metric = 0.005 * kl_loss + 1 / ssim\n",
        "\n",
        "      grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "      self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "      self.total_loss_tracker.update_state(total_loss)\n",
        "      self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "      self.kl_loss_tracker.update_state(kl_loss)\n",
        "      self.ssim_tracker.update_state(ssim)\n",
        "      self.combined_metric_tracker.update_state(combined_kl_ssim_metric)\n",
        "      return {\n",
        "          \"loss\": self.total_loss_tracker.result(),\n",
        "          \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "          \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "          \"ssim\": self.ssim_tracker.result(),\n",
        "          \"combined_kl_ssim_metric\": self.combined_metric_tracker.result(),\n",
        "      }\n",
        "    \n",
        "    def test_step(self, data_and_labels):\n",
        "\n",
        "      #reset just the combined metric and ssim\n",
        "      self.combined_metric_tracker.reset_states()\n",
        "      #self.ssim_tracker.reset_states()\n",
        "      data, pitch_labels = data_and_labels\n",
        "\n",
        "      # Perform forward pass\n",
        "      reconstruction, kl_loss = self(data, training=False)\n",
        "\n",
        "      # Compute loss and metrics\n",
        "      if self.loss_type == \"binary_crossentropy\":\n",
        "          reconstruction_loss = keras.losses.binary_crossentropy(data, reconstruction)\n",
        "      elif self.loss_type == \"mean_squared_error\":\n",
        "          reconstruction_loss = keras.losses.mean_squared_error(data, reconstruction)\n",
        "      else:\n",
        "          raise ValueError(f\"Unsupported loss type: {self.loss_type}\")\n",
        "\n",
        "      # Scale the reconstruction loss by pitch-dependent weight - as the NSynth people did\n",
        "      pitch_weights = tf.vectorized_map(pitch_weight, pitch_labels)\n",
        "      pitch_weights = tf.expand_dims(pitch_weights, axis=-1)\n",
        "      #print(pitch_weights.shape)\n",
        "      #print(reconstruction_loss.shape)\n",
        "      weighted_reconstruction_loss = pitch_weights * reconstruction_loss\n",
        "\n",
        "      # reduce the losses\n",
        "      reconstruction_loss = tf.reduce_mean(\n",
        "          tf.reduce_sum(\n",
        "              reconstruction_loss,\n",
        "              axis=(1, 2),\n",
        "          )\n",
        "      )\n",
        "      weighted_reconstruction_loss = tf.reduce_mean(\n",
        "          tf.reduce_sum(\n",
        "              weighted_reconstruction_loss,\n",
        "              axis=(1, 2),\n",
        "          )\n",
        "      )\n",
        "      # combine the losses\n",
        "      if self.mode == \"VAE\":\n",
        "        total_loss = weighted_reconstruction_loss + 100 * kl_loss\n",
        "      else:\n",
        "        total_loss = weighted_reconstruction_loss\n",
        "\n",
        "      # get ssim metrics\n",
        "      ssim = tf.reduce_mean(tf.image.ssim(data, reconstruction, max_val=1.0))\n",
        "      combined_kl_ssim_metric = 0.005 * kl_loss + 1 / ssim\n",
        "\n",
        "      # Update validation metrics\n",
        "      self.total_loss_tracker.update_state(total_loss)\n",
        "      self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "      self.kl_loss_tracker.update_state(kl_loss)\n",
        "      self.ssim_tracker.update_state(ssim)\n",
        "      self.combined_metric_tracker.update_state(combined_kl_ssim_metric)\n",
        "\n",
        "      return {\n",
        "          \"loss\": self.total_loss_tracker.result(),\n",
        "          \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "          \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "          \"ssim\": self.ssim_tracker.result(),\n",
        "          \"combined_kl_ssim_metric\": self.combined_metric_tracker.result(),\n",
        "      }\n"
      ],
      "metadata": {
        "id": "9_p4Jo6VgyCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_VAE(VAE_parameters_file = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_default_weights_path/default_VAE_parameters.pkl\",\n",
        "             encoder_weights_file = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_default_weights_path/default_encoder_weights.h5\",\n",
        "             decoder_weights_file = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_default_weights_path/default_decoder_weights.h5\",\n",
        "             history_file = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_default_weights_path/default_history.pkl\"\n",
        "             ):\n",
        "  \n",
        "    with open(VAE_parameters_file, \"rb\") as f:\n",
        "        parameters = pickle.load(f)\n",
        "        \n",
        "        input_shape = parameters[0]\n",
        "        conv_filters = parameters[1]\n",
        "        conv_kernels = parameters[2]\n",
        "        conv_strides = parameters[3]\n",
        "        latent_dim = parameters[4]\n",
        "        pre_latent_dense_size_factor = parameters[5]\n",
        "\n",
        "        #account for some older parameter files not having last values\n",
        "        if len(parameters) < 7: #if dont have decoder activation function\n",
        "          decoder_activation = \"sigmoid\" #assume sigmoid\n",
        "        else:\n",
        "          decoder_activation = parameters[6]\n",
        "\n",
        "    encoder,decoder = build_encoder_decoder(input_shape,conv_filters,conv_kernels,conv_strides,latent_dim,pre_latent_dense_size_factor,decoder_activation)\n",
        "    loaded_vae = VAE(encoder,decoder)\n",
        "\n",
        "    loaded_vae.encoder.load_weights(encoder_weights_file)\n",
        "    loaded_vae.decoder.load_weights(decoder_weights_file)\n",
        "\n",
        "    with open(history_file, \"rb\") as f:\n",
        "        history = pickle.load(f)\n",
        "\n",
        "    return loaded_vae, parameters, history, latent_dim\n"
      ],
      "metadata": {
        "id": "CFkgtxo_gqnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAE_parameters_file = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_log_spec_weights/VAE2023-04-21_23-38_parameters.pkl\"\n",
        "encoder_weights_file = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_log_spec_weights/encoder2023-04-21_23-38_weights.h5\"\n",
        "decoder_weights_file = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_log_spec_weights/decoder2023-04-21_23-38_weights.h5\"\n",
        "history_file = \"/content/drive/MyDrive/Variational_Auto_Encoder/Acoustic_default_weights_path/default_history.pkl\"\n",
        "vae,parameters,history,latent_dim = load_VAE(\n",
        "  VAE_parameters_file,\n",
        "  encoder_weights_file,\n",
        "  decoder_weights_file,\n",
        "  history_file\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB0Q15stjlip",
        "outputId": "31f066a8-de4c-4fb6-8fcf-d81a77c5f774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buildmode\n",
            "VAE\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 1024, 192,   0           []                               \n",
            "                                1)]                                                               \n",
            "                                                                                                  \n",
            " encoder_conv_layer_1 (Conv2D)  (None, 512, 96, 64)  1664        ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_LeakyReLU_1 (LeakyReLU  (None, 512, 96, 64)  0          ['encoder_conv_layer_1[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_dropout_1 (Dropout)    (None, 512, 96, 64)  0           ['encoder_LeakyReLU_1[0][0]']    \n",
            "                                                                                                  \n",
            " encoder_BN_1 (BatchNormalizati  (None, 512, 96, 64)  256        ['encoder_dropout_1[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_conv_layer_2 (Conv2D)  (None, 256, 48, 64)  65600       ['encoder_BN_1[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_LeakyReLU_2 (LeakyReLU  (None, 256, 48, 64)  0          ['encoder_conv_layer_2[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_dropout_2 (Dropout)    (None, 256, 48, 64)  0           ['encoder_LeakyReLU_2[0][0]']    \n",
            "                                                                                                  \n",
            " encoder_BN_2 (BatchNormalizati  (None, 256, 48, 64)  256        ['encoder_dropout_2[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_residual_conv_1 (Conv2  (None, 256, 48, 64)  4160       ['encoder_BN_1[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " encoder_residual_add_1 (Add)   (None, 256, 48, 64)  0           ['encoder_BN_2[0][0]',           \n",
            "                                                                  'encoder_residual_conv_1[0][0]']\n",
            "                                                                                                  \n",
            " encoder_conv_layer_3 (Conv2D)  (None, 128, 24, 128  131200      ['encoder_residual_add_1[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " encoder_LeakyReLU_3 (LeakyReLU  (None, 128, 24, 128  0          ['encoder_conv_layer_3[0][0]']   \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " encoder_dropout_3 (Dropout)    (None, 128, 24, 128  0           ['encoder_LeakyReLU_3[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " encoder_BN_3 (BatchNormalizati  (None, 128, 24, 128  512        ['encoder_dropout_3[0][0]']      \n",
            " on)                            )                                                                 \n",
            "                                                                                                  \n",
            " encoder_conv_layer_4 (Conv2D)  (None, 64, 12, 128)  262272      ['encoder_BN_3[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_LeakyReLU_4 (LeakyReLU  (None, 64, 12, 128)  0          ['encoder_conv_layer_4[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_dropout_4 (Dropout)    (None, 64, 12, 128)  0           ['encoder_LeakyReLU_4[0][0]']    \n",
            "                                                                                                  \n",
            " encoder_BN_4 (BatchNormalizati  (None, 64, 12, 128)  512        ['encoder_dropout_4[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_residual_conv_3 (Conv2  (None, 64, 12, 128)  16512      ['encoder_BN_3[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " encoder_residual_add_3 (Add)   (None, 64, 12, 128)  0           ['encoder_BN_4[0][0]',           \n",
            "                                                                  'encoder_residual_conv_3[0][0]']\n",
            "                                                                                                  \n",
            " encoder_conv_layer_5 (Conv2D)  (None, 32, 6, 256)   524544      ['encoder_residual_add_3[0][0]'] \n",
            "                                                                                                  \n",
            " encoder_LeakyReLU_5 (LeakyReLU  (None, 32, 6, 256)  0           ['encoder_conv_layer_5[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_dropout_5 (Dropout)    (None, 32, 6, 256)   0           ['encoder_LeakyReLU_5[0][0]']    \n",
            "                                                                                                  \n",
            " encoder_BN_5 (BatchNormalizati  (None, 32, 6, 256)  1024        ['encoder_dropout_5[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_conv_layer_6 (Conv2D)  (None, 16, 6, 256)   1048832     ['encoder_BN_5[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_LeakyReLU_6 (LeakyReLU  (None, 16, 6, 256)  0           ['encoder_conv_layer_6[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_dropout_6 (Dropout)    (None, 16, 6, 256)   0           ['encoder_LeakyReLU_6[0][0]']    \n",
            "                                                                                                  \n",
            " encoder_BN_6 (BatchNormalizati  (None, 16, 6, 256)  1024        ['encoder_dropout_6[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_residual_conv_5 (Conv2  (None, 16, 6, 256)  65792       ['encoder_BN_5[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " encoder_residual_add_5 (Add)   (None, 16, 6, 256)   0           ['encoder_BN_6[0][0]',           \n",
            "                                                                  'encoder_residual_conv_5[0][0]']\n",
            "                                                                                                  \n",
            " encoder_conv_layer_7 (Conv2D)  (None, 16, 6, 512)   131584      ['encoder_residual_add_5[0][0]'] \n",
            "                                                                                                  \n",
            " encoder_LeakyReLU_7 (LeakyReLU  (None, 16, 6, 512)  0           ['encoder_conv_layer_7[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_dropout_7 (Dropout)    (None, 16, 6, 512)   0           ['encoder_LeakyReLU_7[0][0]']    \n",
            "                                                                                                  \n",
            " encoder_BN_7 (BatchNormalizati  (None, 16, 6, 512)  2048        ['encoder_dropout_7[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_flatten (Flatten)      (None, 49152)        0           ['encoder_BN_7[0][0]']           \n",
            "                                                                                                  \n",
            " encoder_flattened_LeakyReLU (L  (None, 49152)       0           ['encoder_flatten[0][0]']        \n",
            " eakyReLU)                                                                                        \n",
            "                                                                                                  \n",
            " encoder_dropout_flatten (Dropo  (None, 49152)       0           ['encoder_flattened_LeakyReLU[0][\n",
            " ut)                                                             0]']                             \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 8)            393224      ['encoder_dropout_flatten[0][0]']\n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 8)            393224      ['encoder_dropout_flatten[0][0]']\n",
            "                                                                                                  \n",
            " latent_sample (Sampling)       (None, 8)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,044,240\n",
            "Trainable params: 3,041,424\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " decoder_input (InputLayer)     [(None, 8)]          0           []                               \n",
            "                                                                                                  \n",
            " decoder_upsize (Dense)         (None, 49152)        442368      ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_pre_unflatten_LeakyReL  (None, 49152)       0           ['decoder_upsize[0][0]']         \n",
            " U (LeakyReLU)                                                                                    \n",
            "                                                                                                  \n",
            " decoder_dropout_unflatten (Dro  (None, 49152)       0           ['decoder_pre_unflatten_LeakyReLU\n",
            " pout)                                                           [0][0]']                         \n",
            "                                                                                                  \n",
            " decoder_unflatten (Reshape)    (None, 16, 6, 512)   0           ['decoder_dropout_unflatten[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " decoder_conv_layer_1 (Conv2DTr  (None, 16, 6, 512)  262656      ['decoder_unflatten[0][0]']      \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " decoder_LeakyReLU_1 (LeakyReLU  (None, 16, 6, 512)  0           ['decoder_conv_layer_1[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " decoder_dropout_1 (Dropout)    (None, 16, 6, 512)   0           ['decoder_LeakyReLU_1[0][0]']    \n",
            "                                                                                                  \n",
            " decoder_BN_1 (BatchNormalizati  (None, 16, 6, 512)  2048        ['decoder_dropout_1[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_conv_layer_2 (Conv2DTr  (None, 32, 6, 256)  2097408     ['decoder_BN_1[0][0]']           \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " decoder_LeakyReLU_2 (LeakyReLU  (None, 32, 6, 256)  0           ['decoder_conv_layer_2[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " decoder_dropout_2 (Dropout)    (None, 32, 6, 256)   0           ['decoder_LeakyReLU_2[0][0]']    \n",
            "                                                                                                  \n",
            " decoder_BN_2 (BatchNormalizati  (None, 32, 6, 256)  1024        ['decoder_dropout_2[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_residual_conv_1 (Conv2  (None, 32, 6, 256)  131328      ['decoder_BN_1[0][0]']           \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " decoder_residual_add_1 (Add)   (None, 32, 6, 256)   0           ['decoder_BN_2[0][0]',           \n",
            "                                                                  'decoder_residual_conv_1[0][0]']\n",
            "                                                                                                  \n",
            " decoder_conv_layer_3 (Conv2DTr  (None, 64, 12, 256)  1048832    ['decoder_residual_add_1[0][0]'] \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " decoder_LeakyReLU_3 (LeakyReLU  (None, 64, 12, 256)  0          ['decoder_conv_layer_3[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " decoder_dropout_3 (Dropout)    (None, 64, 12, 256)  0           ['decoder_LeakyReLU_3[0][0]']    \n",
            "                                                                                                  \n",
            " decoder_BN_3 (BatchNormalizati  (None, 64, 12, 256)  1024       ['decoder_dropout_3[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_conv_layer_4 (Conv2DTr  (None, 128, 24, 128  524416     ['decoder_BN_3[0][0]']           \n",
            " anspose)                       )                                                                 \n",
            "                                                                                                  \n",
            " decoder_LeakyReLU_4 (LeakyReLU  (None, 128, 24, 128  0          ['decoder_conv_layer_4[0][0]']   \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " decoder_dropout_4 (Dropout)    (None, 128, 24, 128  0           ['decoder_LeakyReLU_4[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " decoder_BN_4 (BatchNormalizati  (None, 128, 24, 128  512        ['decoder_dropout_4[0][0]']      \n",
            " on)                            )                                                                 \n",
            "                                                                                                  \n",
            " decoder_residual_conv_3 (Conv2  (None, 128, 24, 128  32896      ['decoder_BN_3[0][0]']           \n",
            " DTranspose)                    )                                                                 \n",
            "                                                                                                  \n",
            " decoder_residual_add_3 (Add)   (None, 128, 24, 128  0           ['decoder_BN_4[0][0]',           \n",
            "                                )                                 'decoder_residual_conv_3[0][0]']\n",
            "                                                                                                  \n",
            " decoder_conv_layer_5 (Conv2DTr  (None, 256, 48, 128  262272     ['decoder_residual_add_3[0][0]'] \n",
            " anspose)                       )                                                                 \n",
            "                                                                                                  \n",
            " decoder_LeakyReLU_5 (LeakyReLU  (None, 256, 48, 128  0          ['decoder_conv_layer_5[0][0]']   \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " decoder_dropout_5 (Dropout)    (None, 256, 48, 128  0           ['decoder_LeakyReLU_5[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " decoder_BN_5 (BatchNormalizati  (None, 256, 48, 128  512        ['decoder_dropout_5[0][0]']      \n",
            " on)                            )                                                                 \n",
            "                                                                                                  \n",
            " decoder_conv_layer_6 (Conv2DTr  (None, 512, 96, 64)  131136     ['decoder_BN_5[0][0]']           \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " decoder_LeakyReLU_6 (LeakyReLU  (None, 512, 96, 64)  0          ['decoder_conv_layer_6[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " decoder_dropout_6 (Dropout)    (None, 512, 96, 64)  0           ['decoder_LeakyReLU_6[0][0]']    \n",
            "                                                                                                  \n",
            " decoder_BN_6 (BatchNormalizati  (None, 512, 96, 64)  256        ['decoder_dropout_6[0][0]']      \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_residual_conv_5 (Conv2  (None, 512, 96, 64)  8256       ['decoder_BN_5[0][0]']           \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " decoder_residual_add_5 (Add)   (None, 512, 96, 64)  0           ['decoder_BN_6[0][0]',           \n",
            "                                                                  'decoder_residual_conv_5[0][0]']\n",
            "                                                                                                  \n",
            " decoder_output (Conv2DTranspos  (None, 1024, 192, 1  1601       ['decoder_residual_add_5[0][0]'] \n",
            " e)                             )                                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,948,545\n",
            "Trainable params: 4,945,857\n",
            "Non-trainable params: 2,688\n",
            "__________________________________________________________________________________________________\n",
            "VAE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKHf98RHgcQT",
        "outputId": "e9bf31b8-a1e1-46a9-84fc-35cf91093aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 498ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 23.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 390ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:05<00:00, 18.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 371ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 26.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 241ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 283ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 21.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 421ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 22.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 238ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 26.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 250ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 26.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 410ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:06<00:00, 15.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 258ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 26.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 238ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 26.74it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the range and step size for the first latent dimension\n",
        "latent_1_range = np.arange(-10, 12, 2)\n",
        "\n",
        "# Define the remaining latent dimensions (assuming they are 7 in total)\n",
        "latent_dims = 8\n",
        "samplerate = 16000\n",
        "hop_length = 256\n",
        "n_fft = 2048\n",
        "n_iter = 100\n",
        "\n",
        "for i, latent_1_val in enumerate(latent_1_range): #keeping all other at 0\n",
        "    # Generate the latent vector\n",
        "    latent_vec = np.zeros((1,latent_dims))\n",
        "    latent_vec[:,7] = latent_1_val\n",
        "\n",
        "\n",
        "    # Generate the spectrogram\n",
        "    spectrogram = vae.decoder.predict(latent_vec)[0]\n",
        "    spectrogram = np.squeeze(spectrogram)\n",
        "    # Convert the spectrogram to a sound using Griffon Lim\n",
        "    phase = np.random.rand(*spectrogram.shape)\n",
        "    for _ in tqdm(range(n_iter),total=n_iter):\n",
        "        spec = spectrogram * np.exp(1j * phase)\n",
        "        sound = librosa.istft(spec, n_fft = n_fft, hop_length=hop_length)\n",
        "        phase = np.angle(librosa.stft(sound, n_fft=2048, hop_length=hop_length, center = True)[:-1])\n",
        "    \n",
        "    # Normalize the sound to [-1, 1]\n",
        "    sound = sound / np.max(np.abs(sound))\n",
        "    \n",
        "    # Save the sound as a .wav file\n",
        "    filename = f\"/content/drive/MyDrive/Variational_Auto_Encoder/latentspaceexplo/varylatent8/latent8is{latent_1_val}.wav\"\n",
        "    sf.write(filename, sound, samplerate)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(tqdm)"
      ],
      "metadata": {
        "id": "AC1hHT91gjTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_vec = np.zeros((1,latent_dims))\n",
        "latent_vec[:,3] = 10\n",
        "\n",
        "\n",
        "# Generate the spectrogram\n",
        "spectrogram = vae.decoder.predict(latent_vec)[0]\n",
        "spectrogram = np.squeeze(spectrogram)\n",
        "# Convert the spectrogram to a sound using Griffon Lim\n",
        "phase = np.random.rand(*spectrogram.shape)\n",
        "for _ in tqdm(range(n_iter),total=n_iter):\n",
        "    spec = spectrogram * np.exp(1j * phase)\n",
        "    sound = librosa.istft(spec, n_fft = n_fft, hop_length=hop_length)\n",
        "    phase = np.angle(librosa.stft(sound, n_fft=2048, hop_length=hop_length, center = True)[:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz20NdT1ge_a",
        "outputId": "32e07c94-52ea-4b13-88e0-9fe595be5fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 367ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:05<00:00, 18.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(spectrogram), origin='lower')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "_5mpnke_uXdm",
        "outputId": "d4077306-9ee6-4bd1-b2c9-cf0fa6b2fc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f38e6105f40>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}